{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/facumdito/final-pavon/blob/vendel/PRUEBA_M%C3%8DA_PAVON_FINAL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üìå TRABAJO FINAL ICD 2025 - MACHINE LEARNING\n",
        "# Predicci√≥n del rendimiento acad√©mico de estudiantes\n",
        "\n",
        "# =============================\n",
        "# 1. CARGA DE LIBRER√çAS Y DATOS\n",
        "# =============================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Cargar los datos desde el archivo CSV\n",
        "Student_data = pd.read_csv('Student Alcohol Consumption_TF.csv')\n",
        "\n",
        "# Vista general\n",
        "print(\"Primeras filas:\")\n",
        "display(df.head())\n",
        "print(\"\\nInfo:\")\n",
        "df.info()\n",
        "print(\"\\nDescripci√≥n:\")\n",
        "display(df.describe())\n",
        "\n",
        "# Verificar si hay valores nulos\n",
        "print(\"\\nValores nulos por columna:\")\n",
        "Student_data.isnull().sum()\n",
        "\n",
        "# =============================\n",
        "# 2. VISUALIZACI√ìN INICIAL\n",
        "# =============================\n",
        "# Boxplot: consumo de alcohol diario\n",
        "plt.figure(figsize=(7,5))\n",
        "sns.boxplot(x='Dalc', data=df)\n",
        "plt.title('Distribuci√≥n del Consumo Diario de Alcohol')\n",
        "plt.show()\n",
        "\n",
        "# Violinplot: nota final seg√∫n sexo\n",
        "plt.figure(figsize=(7,5))\n",
        "sns.violinplot(x='sex', y='G3', data=df)\n",
        "plt.title('Notas Finales por Sexo')\n",
        "plt.show()\n",
        "\n",
        "# =============================\n",
        "# 3. LIMPIEZA Y BINARIZACI√ìN\n",
        "# =============================\n",
        "# Verificar nulos\n",
        "df.isnull().sum()\n",
        "\n",
        "# Binarizar rendimiento: G3 >= 10 es alto (1), si no es bajo (0)\n",
        "df['performance'] = df['G3'].apply(lambda x: 1 if x >= 10 else 0)\n",
        "\n",
        "# Eliminar columnas redundantes\n",
        "columns_to_drop = ['G1', 'G2', 'G3']\n",
        "df.drop(columns=columns_to_drop, inplace=True)\n",
        "\n",
        "# Codificar variables categ√≥ricas\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "le = LabelEncoder()\n",
        "for col in categorical_cols:\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "\n",
        "# =============================\n",
        "# 4. AN√ÅLISIS DE CORRELACI√ìN\n",
        "# =============================\n",
        "plt.figure(figsize=(15, 10))\n",
        "sns.heatmap(df.corr(), annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n",
        "plt.title(\"Mapa de Calor de Correlaciones\")\n",
        "plt.show()\n",
        "\n",
        "# =============================\n",
        "# 5. DIVISI√ìN DE DATOS\n",
        "# =============================\n",
        "X = df.drop('performance', axis=1)\n",
        "y = df['performance']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# =============================\n",
        "# 6. ENTRENAMIENTO DE MODELOS\n",
        "# =============================\n",
        "# Modelo 1: Regresi√≥n Log√≠stica\n",
        "log_model = LogisticRegression()\n",
        "log_model.fit(X_train, y_train)\n",
        "log_pred = log_model.predict(X_test)\n",
        "\n",
        "# Modelo 2: Random Forest\n",
        "rf_model = RandomForestClassifier()\n",
        "rf_model.fit(X_train, y_train)\n",
        "rf_pred = rf_model.predict(X_test)\n",
        "\n",
        "# =============================\n",
        "# 7. EVALUACI√ìN DE MODELOS\n",
        "# =============================\n",
        "def evaluar_modelo(nombre, y_true, y_pred):\n",
        "    print(f\"\\n\\nüìä Resultados para {nombre}\")\n",
        "    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
        "    print(\"Reporte de Clasificaci√≥n:\")\n",
        "    print(classification_report(y_true, y_pred))\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(f\"Matriz de Confusi√≥n - {nombre}\")\n",
        "    plt.xlabel(\"Predicci√≥n\")\n",
        "    plt.ylabel(\"Real\")\n",
        "    plt.show()\n",
        "\n",
        "# Evaluar ambos\n",
        "evaluar_modelo(\"Regresi√≥n Log√≠stica\", y_test, log_pred)\n",
        "evaluar_modelo(\"Random Forest\", y_test, rf_pred)\n",
        "\n",
        "# =============================\n",
        "# 8. COMPARACI√ìN FINAL\n",
        "# =============================\n",
        "print(\"\\n\\nüìå Comparaci√≥n de Accuracy\")\n",
        "print(f\"Regresi√≥n Log√≠stica: {accuracy_score(y_test, log_pred):.2f}\")\n",
        "print(f\"Random Forest: {accuracy_score(y_test, rf_pred):.2f}\")\n",
        "\n",
        "# =============================\n",
        "# 9. CONCLUSI√ìN\n",
        "# =============================\n",
        "# Esta parte se escribe en el informe aparte o al final del notebook explicando los hallazgos\n",
        "# en lenguaje accesible (ej.: qu√© factores afectan m√°s al rendimiento, qu√© modelo fue mejor, etc.)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "DIbf-TRawm2g",
        "outputId": "699ffc81-cbf6-4249-b067-e159d5e8ee71"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Primeras filas:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4-2683491485.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Vista general\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Primeras filas:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nInfo:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **‚úÖ Conclusi√≥n final del an√°lisis**\n",
        "A lo largo de este trabajo aplicamos t√©cnicas de Machine Learning para predecir si un estudiante tendr√° un rendimiento acad√©mico alto o bajo, utilizando datos reales de estudiantes portugueses.\n",
        "\n",
        "Luego de analizar el dataset, entrenar modelos y evaluar sus resultados, llegamos a varias conclusiones importantes:\n",
        "\n",
        "üß† El rendimiento acad√©mico est√° fuertemente influenciado por factores como la cantidad de materias desaprobadas, las horas de estudio, el consumo de alcohol, las ausencias y el nivel educativo de los padres.\n",
        "\n",
        "üå± Los estudiantes que estudian m√°s, se ausentan menos y tienen mayor apoyo familiar tienden a rendir mejor.\n",
        "\n",
        "‚öôÔ∏è El modelo de Random Forest tuvo mejor desempe√±o que la regresi√≥n log√≠stica, mostrando mayor precisi√≥n y una mejor capacidad de detectar correctamente tanto a los alumnos de alto rendimiento como a los de bajo rendimiento.\n",
        "\n",
        "üìà Este tipo de an√°lisis podr√≠a ayudar en el futuro a identificar a tiempo a estudiantes en riesgo, y tomar decisiones educativas m√°s personalizadas y efectivas.\n",
        "\n"
      ],
      "metadata": {
        "id": "0suDMOfLw5_x"
      }
    }
  ]
}